{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21c0da3b-13d1-4966-ae17-2f6a2ed8c700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from generate_df import table_to_df\n",
    "from IPython.display import display, HTML\n",
    "from tabulate import tabulate\n",
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7184567f-a4cd-4933-ba77-ff3f7961d2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/19 17:37:50 WARN Utils: Your hostname, victor-Lenovo-ideapad-330-15IKB resolves to a loopback address: 127.0.1.1; using 10.0.0.126 instead (on interface wlp2s0)\n",
      "24/06/19 17:37:50 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/19 17:37:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.0.126:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Exemplo Spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7568d1a5f550>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir o caminho do Spark corretamente\n",
    "os.environ['SPARK_HOME'] = '/home/daiane/spark-3.5.1-bin-hadoop3/'\n",
    "\n",
    "# Definir o caminho do Java corretamente\n",
    "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-1.17.0-openjdk-amd64/'\n",
    "\n",
    "# Iniciar uma sessão Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Exemplo Spark\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Testar a sessão Spark\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412e46c4",
   "metadata": {},
   "source": [
    "### Concatenado tabelas e criando df com todos os enderecos \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "627530d3-2874-49da-8408-a5ea665e0f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[cnpj: string, data: string, endereco: string, complemento: string, bairro: string, municipio: string, cep: string, uf: string, address_type: string, number: int, date_end: date]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agencias = table_to_df('finance_raw_data', 'agencias', spark)\n",
    "df_bancos = table_to_df('finance_raw_data', 'bancos', spark)\n",
    "df_cooperativas_credito = table_to_df('finance_raw_data', 'cooperativas_credito', spark)\n",
    "df_sociedades = table_to_df('finance_raw_data', 'sociedades', spark)\n",
    "df_address_adm_consorcio = table_to_df('finance_raw_data', 'administradoras_consorcio', spark)\n",
    "\n",
    "#colunas para a dim_endereco: id, cnpj, address_type, registration_date, date_end, street,\n",
    "#complement, number,  neighborhood, city, postalcode, state\n",
    "\n",
    "colunas = [\"cnpj\", \"data\", \"endereco\",\"complemento\", \"bairro\",  \"municipio\",\"cep\", \"uf\"]\n",
    "\n",
    "\n",
    "df_address_adm_consorcio_selected = df_address_adm_consorcio.select(colunas).withColumn(\"address_type\", F.lit(\"SEDE\"))\n",
    "df_bancos_selected = df_bancos.select(colunas).withColumn(\"address_type\", F.lit(\"SEDE\"))\n",
    "df_cooperativas_credito_selected = df_cooperativas_credito.select(colunas).withColumn(\"address_type\", F.lit(\"SEDE\"))\n",
    "df_sociedades_selected = df_sociedades.select(colunas).withColumn(\"address_type\", F.lit(\"SEDE\"))\n",
    "df_agencias_selected = df_agencias.select(colunas).withColumn(\"address_type\", F.lit(\"AGENCIA\"))\n",
    "\n",
    "dataframes_selected = [df_address_adm_consorcio_selected, df_bancos_selected, df_cooperativas_credito_selected, df_sociedades_selected, df_agencias_selected]\n",
    "\n",
    "dataframes_selected = [\n",
    "    df.withColumn(\"number\", F.lit(None).cast(\"integer\"))\n",
    "      .withColumn(\"date_end\", F.lit(None).cast(\"date\"))\n",
    "    for df in dataframes_selected\n",
    "]\n",
    "\n",
    "def unionAll(dataframes):\n",
    "    return reduce(DataFrame.unionAll, dataframes)\n",
    "\n",
    "df_enderecos = unionAll(dataframes_selected)\n",
    "\n",
    "#colunas_ordem = [\"cnpj\",  \"address_type\", \"data\", \"date_end\", \"endereco\",\"complemento\", \"number\", \"bairro\",  \"municipio\",\"cep\", \"uf\"]\n",
    "\n",
    "#df_enderecos = df_enderecos.select(colunas_ordem)\n",
    "\n",
    "df_enderecos.persist()\n",
    "\n",
    "# df_enderecos.count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6814001e-b3e4-49aa-91ea-0ae3771a7a74",
   "metadata": {},
   "source": [
    "### Tratamento do logradouro e número"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2648d5",
   "metadata": {},
   "source": [
    "#### Padronização dos tipos de logradouros mais comuns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d7e2ccc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[cnpj: string, data: string, endereco: string, complemento: string, bairro: string, municipio: string, cep: string, uf: string, address_type: string, number: int, date_end: date]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tipos_logradouros = [\"AREA\", \"ACESSO\", \"ACAMPAMENTO\", \"AEROPORTO\", \"ALAMEDA\", \"AVENIDA\", \"BLOCO\",\n",
    "                     \"CANAL\", \"CONDOMINIO\", \"DISTRITO\", \"ESTRADA\", \"RUA\", \"VIA\", \"TRAVESSA\"]\n",
    "\n",
    "#amostra_df = df_enderecos.sample(False, 0.5)\n",
    "\n",
    "#df = amostra_df.filter(df_enderecos[\"endereco\"].contains(\"PC. \"))\n",
    "\n",
    "df_tipo_corrigido = df_enderecos.withColumn(\n",
    "    \"endereco\",\n",
    "    F.when(\n",
    "        F.col(\"endereco\").rlike(r\"^R\\. \") | F.col(\"endereco\").rlike(r\"^R \"),\n",
    "        F.regexp_replace(F.col(\"endereco\"), r\"^R\\.? \", \"RUA \")\n",
    "    ).when(\n",
    "        F.col(\"endereco\").rlike(r\"^AV\\. \") | F.col(\"endereco\").rlike(r\"^AV \"),\n",
    "        F.regexp_replace(F.col(\"endereco\"), r\"^AV\\.? \", \"AVENIDA \")\n",
    "    ).when(\n",
    "        F.col(\"endereco\").rlike(r\"^TV\\. \") | F.col(\"endereco\").rlike(r\"^TV \"),\n",
    "        F.regexp_replace(F.col(\"endereco\"), r\"^TV\\.? \", \"TRAVESSA \")\n",
    "    ).when(\n",
    "        F.col(\"endereco\").rlike(r\"^PC \"),\n",
    "        F.regexp_replace(F.col(\"endereco\"), r\"^PC \", \"PRACA \")\n",
    "    ).otherwise(F.col(\"endereco\"))\n",
    ")\n",
    "\n",
    "df_tipo_corrigido.persist()\n",
    "\n",
    "\n",
    "# table = tabulate(df_tipo_corrigido.collect(), headers=df_enderecos_corrigido.columns, tablefmt='html')\n",
    "\n",
    " #table = tabulate(amostra_df.collect(), headers=amostra_df.columns, tablefmt='html')\n",
    "\n",
    "\n",
    "# display(HTML(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9fdab8",
   "metadata": {},
   "source": [
    "#### Tratamento do número"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43db6493",
   "metadata": {},
   "source": [
    "Identificando o número na coluna \"endereco\" e copiando-o pra coluna \"number\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd8d1267",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/19 17:38:57 WARN TaskSetManager: Stage 0 contains a task of very large size (1496 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/06/19 17:39:00 WARN TaskSetManager: Stage 1 contains a task of very large size (1496 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/06/19 17:39:02 WARN TaskSetManager: Stage 2 contains a task of very large size (1496 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/06/19 17:39:04 WARN TaskSetManager: Stage 3 contains a task of very large size (1496 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/06/19 17:39:05 WARN TaskSetManager: Stage 6 contains a task of very large size (1496 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/06/19 17:39:06 WARN TaskSetManager: Stage 9 contains a task of very large size (1496 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros não vazios: 46521 (68.00%)\n",
      "Registros vazios: 21893 (32.00%)\n"
     ]
    }
   ],
   "source": [
    "# amostra_df = df_tipo_corrigido.sample(False, 0.1)\n",
    "\n",
    "regex = r\"(\\d+(?:\\.\\d+)?)\"\n",
    "\n",
    "tipos_logradouros = [\"AREA\", \"ACESSO\", \"ACAMPAMENTO\", \"AEROPORTO\", \"ALAMEDA\", \"AVENIDA\", \"BLOCO\",\n",
    "                     \"CANAL\", \"CONDOMINIO\", \"DISTRITO\", \"ESTRADA\", \"RUA\", \"VIA\", \"TRAVESSA\"]\n",
    "\n",
    "\n",
    "df_numero = df_tipo_corrigido.withColumn(\"number\",\n",
    "    F.when(\n",
    "        (F.col(\"endereco\").like(\"%BR %\")) |\n",
    "        (F.col(\"endereco\").like(\"%BR/%\")) |\n",
    "        (F.col(\"endereco\").like(\"%RODOVIA%\")) |\n",
    "        (F.col(\"endereco\").rlike(r\"^\\b(\" + \"|\".join(tipos_logradouros) + r\")\\b \\d+\")) |\n",
    "        (F.col(\"endereco\").rlike(r\"^\\b(\" + \"|\".join(tipos_logradouros) + r\")\\b \\d+[A-Z]*$\")) |\n",
    "        ((F.col(\"endereco\").like(\"%QUADRA%\")) & (~F.col(\"endereco\").like(\"%LOTE%\"))) |\n",
    "        (F.col(\"endereco\").rlike(r'\\d+-\\d+')),\n",
    "        \"\"\n",
    "    ).otherwise(\n",
    "        F.when(\n",
    "            (F.col(\"endereco\").like(\"%QUADRA%\")) & (F.col(\"endereco\").like(\"%LOTE%\")),\n",
    "            F.regexp_extract(F.col(\"endereco\"), r\".LOTE (\\d+)\", 1)\n",
    "        ).when(\n",
    "            (F.col(\"endereco\").like(\"%N %\")) | (F.col(\"endereco\").like(\"%N.\")) | (F.col(\"endereco\").like(\"%Nº\")),\n",
    "            F.regexp_extract(F.col(\"endereco\"), r\"N[ .º]?(\\d+)\", 1)\n",
    "        ).otherwise(\n",
    "            F.regexp_extract(F.col(\"endereco\"), regex, 0)\n",
    "        )\n",
    "    )\n",
    ").withColumn(\"endereco\",\n",
    "    F.when(\n",
    "        (F.col(\"number\") != \"\") &\n",
    "        ~(F.col(\"endereco\").rlike(r'\\d+-\\d+')),  \n",
    "        F.regexp_replace(F.col(\"endereco\"), F.col(\"number\"), \"EXTRAIRAPARTIRDAQUI\")\n",
    "    ).otherwise(F.col(\"endereco\")))\n",
    "\n",
    "\n",
    "\n",
    "df_numero.persist()\n",
    "\n",
    "\n",
    "# df_numero_tratado_ = df_numero_tratado.filter(df_enderecos[\"endereco\"].contains(\"EXTRAIRAPARTIRDAQUI-\"))\n",
    "\n",
    "# rows = df_numero_tratado.collect()\n",
    "\n",
    "# columns = df_numero_tratado.columns\n",
    "\n",
    "# table = tabulate(rows, headers=columns, tablefmt='html')\n",
    "\n",
    "# display(HTML(table))\n",
    "\n",
    "\n",
    "non_empty_count = df_numero.filter((F.col(\"number\").isNotNull()) & (F.col(\"number\") != \"\")).count()\n",
    "\n",
    "empty_count = df_numero.filter((F.col(\"number\").isNull()) | (F.col(\"number\") == \"\")).count()\n",
    "\n",
    "total_count = df_numero.count()\n",
    "\n",
    "non_empty_percentage = (non_empty_count / total_count) * 100\n",
    "empty_percentage = (empty_count / total_count) * 100\n",
    "\n",
    "\n",
    "print(f\"Registros não vazios: {non_empty_count} ({non_empty_percentage:.2f}%)\")\n",
    "print(f\"Registros vazios: {empty_count} ({empty_percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009d4495-9ac5-4a02-9722-adf91ccb78e2",
   "metadata": {},
   "source": [
    "- Adicionando tudo que vem após o número em uma coluna temporária onde serão removidos os caracteres especias e padronizados para concatenar com a coluna complemento\n",
    "- excluindo o texto \"EXTRAIRAPARTIRDAQUI\" usado pra identificar o número no endereço\n",
    "- limpando caracteres especiais do final da string do campo endereco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8241731",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/19 17:39:12 WARN TaskSetManager: Stage 12 contains a task of very large size (1496 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pattern = \"EXTRAIRAPARTIRDAQUI(.*)\"\n",
    "\n",
    "df_pos_numero = df_numero.withColumn(\"apos_numero\", F.regexp_extract(\"endereco\", pattern, 1))\n",
    "\n",
    "\n",
    "df_pos_numero_tratado = df_pos_numero.withColumn(\"apos_numero\", F.regexp_replace(F.col(\"apos_numero\"), r'^[^a-zA-Z0-9]+', ''))\n",
    "\n",
    "# Adicionar \" - \" ao final se a string não ficar vazia após a limpeza\n",
    "df_pos_numero_tratado = df_pos_numero_tratado.withColumn(\n",
    "    \"apos_numero\",\n",
    "    F.when(F.col(\"apos_numero\") != '', F.concat(F.col(\"apos_numero\"), F.lit(' - '))).otherwise('')\n",
    ")\n",
    "\n",
    "#concatenando a coluna temporario tratada com o complemento\n",
    "df_pos_numero_tratado = df_pos_numero_tratado.withColumn(\"complemento\",\n",
    "                                                       F.concat(F.col(\"apos_numero\"), F.col(\"complemento\")))\n",
    "\n",
    "df_endereco_sem_numero = df_pos_numero_tratado.withColumn(\"endereco\",\n",
    "                                                      F.regexp_replace(F.col(\"endereco\"), pattern, \"\"))    \n",
    "\n",
    "caractere_especial = r'[^\\w\\s]$'\n",
    "\n",
    "df_endereco_sem_especial = df_endereco_sem_numero.withColumn(\"endereco\", \n",
    "                        F.regexp_replace(F.trim(F.col(\"endereco\")), caractere_especial, \"\"))                                                                       \n",
    "                                                                                   \n",
    "df_pos_numero_tratado = df_endereco_sem_especial.drop(\"apos_numero\")\n",
    "\n",
    "df_pos_numero_tratado.persist()\n",
    "\n",
    "df_pos_numero_tratado.createOrReplaceTempView(\"view_temporariaa\")\n",
    "\n",
    "df = spark.sql(\"SELECT endereco, number, complemento, data FROM view_temporariaa\").limit(50)\n",
    "\n",
    "# df = spark.sql(\" SELECT apos_numero, COUNT(*) as freq from view_temporariaa group by apos_numero order by freq desc \").show(50)\n",
    "\n",
    "# df = spark.sql(\"select * from view_temporariaa \")\n",
    "\n",
    "table = tabulate(df.collect(), headers=df.columns, tablefmt='html')\n",
    "\n",
    "# display(HTML(table))\n",
    "\n",
    "# df_pos_numero_tratado.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34711168-2876-4525-9ba1-34d029a6e3c7",
   "metadata": {},
   "source": [
    "#### Removendo acentos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d4a93de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting unidecode\n",
      "  Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 KB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: unidecode\n",
      "Successfully installed unidecode-1.3.8\n"
     ]
    }
   ],
   "source": [
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f261d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_accent_(texto):\n",
    "    return unidecode(texto) if texto else None\n",
    "\n",
    "clean_accent = F.udf(clean_accent_, F.StringType())\n",
    "\n",
    "df_sem_acento = df_pos_numero_tratado.withColumn(\"endereco\", F.upper(clean_accent(F.col(\"endereco\"))))\\\n",
    "                                     .withColumn(\"complemento\", F.upper(clean_accent(F.col(\"complemento\"))))\\\n",
    "                                     .withColumn(\"uf\", F.upper(clean_accent(F.col(\"uf\"))))\\\n",
    "                                    .withColumn(\"municipio\", F.upper(clean_accent(F.col(\"municipio\"))))\n",
    "\n",
    "# df_sem_acento.show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc359ff6-9192-435c-a9ed-4ec48a836d46",
   "metadata": {},
   "source": [
    "### Duplicação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23dd9b89-955e-4525-b2bb-9361176cfdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/19 18:31:09 WARN TaskSetManager: Stage 14 contains a task of very large size (1496 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 14:===============================================>        (17 + 3) / 20]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Não há linhas duplicadas no DataFrame.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "all_columns = df_sem_acento.columns\n",
    "\n",
    "colunas_ = list(filter(lambda col: col != \"data\", all_columns))\n",
    "\n",
    "df_unique = df_sem_acento.dropDuplicates(subset=colunas_)\n",
    "\n",
    "df_grouped = df_unique.groupBy(colunas_).count()\n",
    "\n",
    "df_duplicates = df_grouped.filter(F.col(\"count\") > 1)\n",
    "\n",
    "\n",
    "if df_duplicates.count() > 0:\n",
    "    print(\"Há linhas duplicadas no DataFrame.\")\n",
    "    print(df_duplicates.count() )\n",
    "else:\n",
    "    print(\"Não há linhas duplicadas no DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1b481b-eec3-4559-a4a6-81987d907a80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eac35f94-557a-4354-942c-c79dd25b9b1c",
   "metadata": {},
   "source": [
    "### Fomatação da data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2e5e770-e87e-4f05-a1f4-761ed3bb0c5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_data_formatada = df_unique.withColumn(\"data\", F.to_date(F.col(\"data\")))\n",
    "\n",
    "df_data_formatada_sample = df_data_formatada.sample(False, 0.1)\n",
    "\n",
    "# table = tabulate(df_data_formatada_sample.collect(), headers=df_data_formatada_sample.columns, tablefmt='html')\n",
    "\n",
    "# display(HTML(table))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df911f8-c12a-4384-806e-754e6736b26e",
   "metadata": {},
   "source": [
    "#### Renomear colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80838581-b16d-46bd-a714-c30c9c926cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomear as colunas 'id' para 'codigo' e 'nome' para 'nome_completo'\n",
    "\n",
    "df_final = df_data_formatada.select(df_data_formatada[\"data\"].alias(\"registration_date\"),\n",
    "                                    df_data_formatada[\"endereco\"].alias(\"street\"),\n",
    "                                     df_data_formatada[\"complemento\"].alias(\"complement\"),\n",
    "                                    df_data_formatada[\"bairro\"].alias(\"neighborhood\"),\n",
    "                                     df_data_formatada[\"municipio\"].alias(\"city\"),\n",
    "                                    df_data_formatada[\"cep\"].alias(\"postalcode\"),\n",
    "                                     df_data_formatada[\"uf\"].alias(\"state\"),\n",
    "                                   df_data_formatada[\"cnpj\"],\n",
    "                                   df_data_formatada[\"address_type\"],\n",
    "                                   df_data_formatada[\"number\"],\n",
    "                                   df_data_formatada[\"date_end\"])\n",
    "# df_final.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96244b7b-ed03-4921-8098-abccc818efbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cnpj: string (nullable = true)\n",
      " |-- data: date (nullable = true)\n",
      " |-- endereco: string (nullable = true)\n",
      " |-- complemento: string (nullable = true)\n",
      " |-- bairro: string (nullable = true)\n",
      " |-- municipio: string (nullable = true)\n",
      " |-- cep: string (nullable = true)\n",
      " |-- uf: string (nullable = true)\n",
      " |-- address_type: string (nullable = false)\n",
      " |-- number: string (nullable = true)\n",
      " |-- date_end: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# jdbc_properties = {\n",
    "#     \"user\": \"seu_usuario\",\n",
    "#     \"password\": \"sua_senha\",\n",
    "#     \"driver\": \"org.postgresql.Driver\"\n",
    "# }\n",
    "\n",
    "# # Escreve o DataFrame no PostgreSQL\n",
    "# df.write.jdbc(url=jdbc_url, table=\"nome_da_tabela\", mode=\"overwrite\", properties=jdbc_properties)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7f8971-905d-4d8d-af35-e3b1e48fc9df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabbd8fc-8378-431d-b497-e2a60236735f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
